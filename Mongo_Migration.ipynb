{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ba5529a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e3c5d4",
   "metadata": {},
   "source": [
    "JSONL for single collection schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5194d407",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_country_code_map(country_file_path):\n",
    "    \"\"\"\n",
    "    Reads the Country-Code.csv file and returns a dictionary\n",
    "    mapping country codes (as integers) to country names.\n",
    "    \"\"\"\n",
    "    country_map = {}\n",
    "    try:\n",
    "        with open(country_file_path, mode='r', encoding='utf-8') as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            for row in reader:\n",
    "                try:\n",
    "                    # Assuming column names are 'Country Code' and 'Country'\n",
    "                    country_code = int(row['country_code'])\n",
    "                    country_map[country_code] = row['country']\n",
    "                except ValueError:\n",
    "                    print(f\"Warning: Could not parse country code in {country_file_path}: {row['country_code']}\")\n",
    "                except KeyError:\n",
    "                    print(f\"Warning: 'Country Code' or 'Country' column missing in {country_file_path}.\")\n",
    "                    return None # Indicate critical error\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Country code file not found at {country_file_path}\")\n",
    "        return None\n",
    "    return country_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eba506e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(data_file_path, country_map, output_file_path):\n",
    "    \"\"\"\n",
    "    Reads new_dataset.csv, transforms each row into the desired\n",
    "    MongoDB document structure, and writes it to an output JSON Lines file.\n",
    "    \"\"\"\n",
    "    if country_map is None:\n",
    "        print(\"Error: Country map is not available. Aborting transformation.\")\n",
    "        return\n",
    "\n",
    "    transformed_count = 0\n",
    "    try:\n",
    "        with open(data_file_path, mode='r', encoding='utf-8') as infile, \\\n",
    "             open(output_file_path, mode='w', encoding='utf-8') as outfile:\n",
    "            \n",
    "            reader = csv.DictReader(infile)\n",
    "            \n",
    "            # Verify expected columns (adjust based on your actual new_dataset.csv headers)\n",
    "            expected_headers = [\n",
    "                'restaurant_id', 'restaurant_name', 'country_code', 'city', 'address',\n",
    "                'locality', 'locality_verbose', 'longitude', 'latitude', 'cuisines',\n",
    "                'average_cost_for_two', 'currency', 'has_table_booking', 'has_online_delivery',\n",
    "                'is_delivering_now', 'switch_to_order_menu', 'price_range', 'aggregate_rating',\n",
    "                'rating_color', 'rating_text', 'votes'\n",
    "            ]\n",
    "            missing_headers = [h for h in expected_headers if h not in reader.fieldnames]\n",
    "            if missing_headers:\n",
    "                print(f\"Warning: The following expected columns are missing from {data_file_path}: {', '.join(missing_headers)}\")\n",
    "                print(\"Please ensure your CSV column names match. Script will attempt to proceed but may fail or produce incomplete documents.\")\n",
    "\n",
    "            for row in reader:\n",
    "                try:\n",
    "                    country_code_val = int(row.get('country_code', 0)) # Default to 0 if missing, handle error below\n",
    "                    \n",
    "                    # Handle cuisines: split by comma, strip whitespace\n",
    "                    cuisines_str = row.get('cuisines', '')\n",
    "                    cuisines_list = [c.strip() for c in cuisines_str.split(',') if c.strip()] if cuisines_str else []\n",
    "\n",
    "                    mongo_doc = {\n",
    "                        # Using original 'Restaurant ID' as a field, MongoDB will generate its own _id\n",
    "                        \"restaurant_id\": int(row.get('restaurant_id')),\n",
    "                        \"restaurant_name\": row.get('restaurant_name', ''),\n",
    "                        \"address\": {\n",
    "                            \"street\": row.get('address', ''),\n",
    "                            \"city\": row.get('city', ''),\n",
    "                            \"locality\": row.get('locality', ''),\n",
    "                            \"locality_verbose\": row.get('locality_verbose', ''),\n",
    "                            \"country_code\": country_code_val,\n",
    "                            \"country_name\": country_map.get(country_code_val, \"Unknown Country\") # Get country name from map\n",
    "                        },\n",
    "                        \"location\": {\n",
    "                            \"type\": \"Point\",\n",
    "                            \"coordinates\": [\n",
    "                                float(row.get('longitude', 0.0)),\n",
    "                                float(row.get('latitude', 0.0))\n",
    "                            ]\n",
    "                        },\n",
    "                        \"cuisines\": cuisines_list,\n",
    "                        \"average_cost_for_two\": int(row.get('average_cost_for_two', 0)),\n",
    "                        \"rating_details\": {\n",
    "                            \"aggregate_rating\": float(row.get('aggregate_rating', 0.0)),\n",
    "                            \"rating_color\": row.get('rating_color', ''),\n",
    "                            \"rating_text\": row.get('rating_text', ''),\n",
    "                            \"votes\": int(row.get('votes', 0)),\n",
    "                            \"price_range\": int(row.get('price_range', 0)),\n",
    "                            \"currency\": row.get('currency', '')\n",
    "                        }\n",
    "                        # The fields 'Has Table booking' and 'Has Online delivery' were noted\n",
    "                        # as dropped in your Dataset_EDA.ipynb. If they exist in your\n",
    "                        # new_dataset.csv and you want to include them, add them here.\n",
    "                        # Example:\n",
    "                        # \"has_table_booking\": True if row.get('Has Table booking', 'No').lower() == 'yes' else False,\n",
    "                        # \"has_online_delivery\": True if row.get('Has Online delivery', 'No').lower() == 'yes' else False,\n",
    "                    }\n",
    "                    \n",
    "                    # Write the JSON document to the output file, one per line\n",
    "                    outfile.write(json.dumps(mongo_doc) + '\\n')\n",
    "                    transformed_count += 1\n",
    "                except ValueError as ve:\n",
    "                    print(f\"Warning: Skipping row due to data conversion error (ValueError): {ve} - Row: {row}\")\n",
    "                except KeyError as ke:\n",
    "                    print(f\"Warning: Skipping row due to missing key (KeyError): {ke} - Row: {row}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Skipping row due to unexpected error: {e} - Row: {row}\")\n",
    "            \n",
    "            print(f\"Successfully transformed {transformed_count} documents.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Data file not found at {data_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during transformation: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93138efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data migration process...\n",
      "Country code map created with 15 entries.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully transformed 9551 documents.\n",
      "Transformation complete. Output written to restaurants_mongo.jsonl\n",
      "You can now import 'restaurants_mongo.jsonl' into MongoDB.\n"
     ]
    }
   ],
   "source": [
    "country_csv_file = 'Country-Code.csv' # Ensure this file is in the same directory or provide full path\n",
    "data_csv_file = 'new_dataset.csv'     # Ensure this file is in the same directory or provide full path\n",
    "output_jsonl_file = 'restaurants_mongo.jsonl'\n",
    "\n",
    "print(\"Starting data migration process...\")\n",
    "\n",
    "country_mapping = create_country_code_map(country_csv_file)\n",
    "\n",
    "if country_mapping:\n",
    "    print(f\"Country code map created with {len(country_mapping)} entries.\")\n",
    "    transform_data(data_csv_file, country_mapping, output_jsonl_file)\n",
    "    print(f\"Transformation complete. Output written to {output_jsonl_file}\")\n",
    "    print(f\"You can now import '{output_jsonl_file}' into MongoDB.\")\n",
    "else:\n",
    "    print(\"Could not create country mapping. Please check 'Country-Code.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b85953",
   "metadata": {},
   "source": [
    "JSONL for double collection schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4157fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data migration process for two collections...\n",
      "Country code map created with 15 entries.\n",
      "\n",
      "Successfully transformed 9551 documents for 'restaurants_main'.\n",
      "Successfully transformed 9551 documents for 'restaurant_live_ratings'.\n",
      "\n",
      "Transformation complete.\n",
      "Output for main data: restaurants_main.jsonl\n",
      "Output for live ratings data: restaurant_live_ratings.jsonl\n",
      "\n",
      "You can now import these JSONL files into their respective MongoDB collections.\n",
      "Remember to use the correct database and collection names in your 'mongoimport' commands.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "def create_country_code_map(country_file_path):\n",
    "    \"\"\"\n",
    "    Reads the Country-Code.csv file and returns a dictionary\n",
    "    mapping country codes (as integers) to country names.\n",
    "    \"\"\"\n",
    "    country_map = {}\n",
    "    try:\n",
    "        with open(country_file_path, mode='r', encoding='utf-8') as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            # Assuming 'Country-Code.csv' headers are 'Country Code' and 'Country'\n",
    "            # Adjust if your Country-Code.csv has different headers (e.g., lowercase with underscore)\n",
    "            csv_country_code_header = 'country_code' # Standard Zomato CSV header for this file\n",
    "            csv_country_name_header = 'country'      # Standard Zomato CSV header for this file\n",
    "\n",
    "            if csv_country_code_header not in reader.fieldnames or csv_country_name_header not in reader.fieldnames:\n",
    "                print(f\"Error: Expected columns '{csv_country_code_header}' or '{csv_country_name_header}' missing in {country_file_path}.\")\n",
    "                print(f\"Actual headers: {reader.fieldnames}\")\n",
    "                return None\n",
    "            for row in reader:\n",
    "                try:\n",
    "                    country_code = int(row[csv_country_code_header])\n",
    "                    country_map[country_code] = row[csv_country_name_header]\n",
    "                except ValueError:\n",
    "                    print(f\"Warning: Could not parse country code in {country_file_path} for row: {row}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Country code file not found at {country_file_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred while reading {country_file_path}: {e}\")\n",
    "        return None\n",
    "    return country_map\n",
    "\n",
    "def is_valid_longitude(lon_str):\n",
    "    try:\n",
    "        lon = float(lon_str)\n",
    "        return -180 <= lon <= 180\n",
    "    except (ValueError, TypeError):\n",
    "        return False\n",
    "\n",
    "def is_valid_latitude(lat_str):\n",
    "    try:\n",
    "        lat = float(lat_str)\n",
    "        return -90 <= lat <= 90\n",
    "    except (ValueError, TypeError):\n",
    "        return False\n",
    "\n",
    "def transform_data_to_two_collections(data_file_path, country_map, output_main_file, output_ratings_file):\n",
    "    \"\"\"\n",
    "    Reads new_dataset.csv, transforms each row into two document structures\n",
    "    (for restaurants_main and restaurant_live_ratings),\n",
    "    and writes them to their respective output JSON Lines files.\n",
    "    Uses the provided csv_headers mapping.\n",
    "    \"\"\"\n",
    "    if country_map is None:\n",
    "        print(\"Error: Country map is not available. Aborting transformation.\")\n",
    "        return\n",
    "\n",
    "    count_main = 0\n",
    "    count_ratings = 0\n",
    "    \n",
    "    # Corrected csv_headers based on your input\n",
    "    csv_headers = {\n",
    "        'id': 'restaurant_id',\n",
    "        'name': 'restaurant_name',\n",
    "        'country_code_csv': 'country_code', # CSV header for country code in new_dataset.csv\n",
    "        'city': 'city', # Corrected: Assuming 'city' not 'City' based on other keys\n",
    "        'address_street_csv': 'address',\n",
    "        'locality': 'locality',\n",
    "        'locality_verbose': 'locality_verbose',\n",
    "        'longitude_csv': 'longitude',\n",
    "        'latitude_csv': 'latitude',\n",
    "        'cuisines_csv': 'cuisines',\n",
    "        'avg_cost': 'average_cost_for_two',\n",
    "        'currency_csv': 'currency',\n",
    "        'price_range_csv': 'price_range',\n",
    "        'agg_rating_csv': 'aggregate_rating',\n",
    "        'rating_color_csv': 'rating_color',\n",
    "        'rating_text_csv': 'rating_text',\n",
    "        'votes_csv': 'votes' # Note: your example had 'votes_csv': 'votes', I kept 'votes_csv' as the key\n",
    "                               # for consistency, its value is 'votes' which is the CSV header.\n",
    "        # Optional fields (if they exist in your new_dataset.csv)\n",
    "        # 'has_table_booking_csv': 'has_table_booking',\n",
    "        # 'has_online_delivery_csv': 'has_online_delivery',\n",
    "    }\n",
    "\n",
    "\n",
    "    try:\n",
    "        with open(data_file_path, mode='r', encoding='utf-8') as infile, \\\n",
    "             open(output_main_file, mode='w', encoding='utf-8') as outfile_main, \\\n",
    "             open(output_ratings_file, mode='w', encoding='utf-8') as outfile_ratings:\n",
    "\n",
    "            reader = csv.DictReader(infile)\n",
    "            \n",
    "            # Verify that all keys used from csv_headers actually exist in the reader's fieldnames\n",
    "            missing_csv_headers_in_file = [header_name for key, header_name in csv_headers.items() if header_name not in reader.fieldnames]\n",
    "            if missing_csv_headers_in_file:\n",
    "                print(f\"Critical Warning: The following CSV column names specified in 'csv_headers' were NOT FOUND in '{data_file_path}': {', '.join(missing_csv_headers_in_file)}\")\n",
    "                print(f\"Actual headers found in CSV: {reader.fieldnames}\")\n",
    "                print(\"Please correct the 'csv_headers' dictionary in the script to match your CSV file EXACTLY or ensure your CSV file has these columns.\")\n",
    "                # Decide if you want to abort or proceed with potential errors\n",
    "                # return # Uncomment to abort if headers are missing\n",
    "\n",
    "            for row_num, row in enumerate(reader, 1):\n",
    "                try:\n",
    "                    restaurant_id_val = int(row.get(csv_headers['id']))\n",
    "                    \n",
    "                    lon_str = row.get(csv_headers['longitude_csv'])\n",
    "                    lat_str = row.get(csv_headers['latitude_csv'])\n",
    "                    \n",
    "                    coordinates_val = [400, 400] \n",
    "                    if is_valid_longitude(lon_str) and is_valid_latitude(lat_str):\n",
    "                        coordinates_val = [float(lon_str), float(lat_str)]\n",
    "                    else:\n",
    "                        print(f\"Info: Row {row_num} (ID: {restaurant_id_val}) - Invalid coordinates ('{lon_str}', '{lat_str}'). Using marker [400, 400].\")\n",
    "\n",
    "                    cuisines_str = row.get(csv_headers['cuisines_csv'], '')\n",
    "                    cuisines_list = [c.strip() for c in cuisines_str.split(',') if c.strip()] if cuisines_str else []\n",
    "                    \n",
    "                    country_code_val = 0\n",
    "                    try:\n",
    "                        # Use the mapping for country_code from csv_headers\n",
    "                        country_code_from_csv_str = row.get(csv_headers['country_code_csv'], '0')\n",
    "                        if country_code_from_csv_str and country_code_from_csv_str.strip():\n",
    "                             country_code_val = int(float(country_code_from_csv_str)) # Handle potential float like \"1.0\"\n",
    "                        else:\n",
    "                            country_code_val = 0 # Default if empty or missing\n",
    "                    except ValueError:\n",
    "                        print(f\"Warning: Row {row_num} (ID: {restaurant_id_val}) - Invalid Country Code '{row.get(csv_headers['country_code_csv'])}'. Using 0.\")\n",
    "                    country_name_val = country_map.get(country_code_val, \"Unknown Country\")\n",
    "\n",
    "                    main_doc = {\n",
    "                        \"restaurant_id\": restaurant_id_val,\n",
    "                        \"restaurant_name\": row.get(csv_headers['name'], ''),\n",
    "                        \"address\": {\n",
    "                            \"street\": row.get(csv_headers['address_street_csv'], ''),\n",
    "                            \"city\": row.get(csv_headers['city'], ''),\n",
    "                            \"locality\": row.get(csv_headers['locality'], ''),\n",
    "                            \"locality_verbose\": row.get(csv_headers['locality_verbose'], ''),\n",
    "                            \"country_code\": country_code_val,\n",
    "                            \"country_name\": country_name_val\n",
    "                        },\n",
    "                        \"location\": {\n",
    "                            \"type\": \"Point\",\n",
    "                            \"coordinates\": coordinates_val\n",
    "                        },\n",
    "                        \"cuisines\": cuisines_list,\n",
    "                        \"average_cost_for_two\": int(row.get(csv_headers['avg_cost'], 0)) if row.get(csv_headers['avg_cost']) else None,\n",
    "                        \"rating_details\": {\n",
    "                            \"rating_color\": row.get(csv_headers['rating_color_csv'], ''),\n",
    "                            \"rating_text\": row.get(csv_headers['rating_text_csv'], ''),\n",
    "                            \"price_range\": int(row.get(csv_headers['price_range_csv'], 0)) if row.get(csv_headers['price_range_csv']) else 0,\n",
    "                            \"currency\": row.get(csv_headers['currency_csv'], '')\n",
    "                        }\n",
    "                        # Optional fields:\n",
    "                        # \"has_table_booking\": True if row.get(csv_headers.get('has_table_booking_csv'), 'No').lower() == 'yes' else False,\n",
    "                        # \"has_online_delivery\": True if row.get(csv_headers.get('has_online_delivery_csv'), 'No').lower() == 'yes' else False,\n",
    "                    }\n",
    "                    # Add optional fields only if their CSV header name is defined in csv_headers\n",
    "                    if 'has_table_booking_csv' in csv_headers and csv_headers['has_table_booking_csv'] in row:\n",
    "                         main_doc[\"has_table_booking\"] = True if row.get(csv_headers['has_table_booking_csv'], 'No').lower() == 'yes' else False\n",
    "                    if 'has_online_delivery_csv' in csv_headers and csv_headers['has_online_delivery_csv'] in row:\n",
    "                         main_doc[\"has_online_delivery\"] = True if row.get(csv_headers['has_online_delivery_csv'], 'No').lower() == 'yes' else False\n",
    "                        \n",
    "                    outfile_main.write(json.dumps(main_doc) + '\\n')\n",
    "                    count_main += 1\n",
    "\n",
    "                    ratings_doc = {\n",
    "                        \"restaurant_id\": restaurant_id_val,\n",
    "                        \"aggregate_rating\": float(row.get(csv_headers['agg_rating_csv'], 0.0)) if row.get(csv_headers['agg_rating_csv']) else 0.0,\n",
    "                        \"votes\": int(row.get(csv_headers['votes_csv'], 0)) if row.get(csv_headers['votes_csv']) else 0,\n",
    "                        \"last_updated_timestamp\": datetime.now(timezone.utc).isoformat()\n",
    "                    }\n",
    "                    outfile_ratings.write(json.dumps(ratings_doc) + '\\n')\n",
    "                    count_ratings += 1\n",
    "\n",
    "                except ValueError as ve:\n",
    "                    print(f\"Warning: Row {row_num} (ID: {row.get(csv_headers.get('id', 'UNKNOWN_ID'))}) - Skipping due to data conversion error (ValueError): {ve} - Row data excerpt: { {k: row.get(v) for k,v in list(csv_headers.items())[:3]} }...\")\n",
    "                except KeyError as ke: # Should be caught by the initial header check now\n",
    "                    print(f\"Warning: Row {row_num} (ID: {row.get(csv_headers.get('id', 'UNKNOWN_ID'))}) - Skipping due to missing key (KeyError): {ke}. Check csv_headers dictionary and CSV file headers. Row data excerpt: { {k: row.get(v) for k,v in list(csv_headers.items())[:3]} }...\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Row {row_num} (ID: {row.get(csv_headers.get('id', 'UNKNOWN_ID'))}) - Skipping due to unexpected error: {e} - Row data excerpt: { {k: row.get(v) for k,v in list(csv_headers.items())[:3]} }...\")\n",
    "            \n",
    "            print(f\"\\nSuccessfully transformed {count_main} documents for 'restaurants_main'.\")\n",
    "            print(f\"Successfully transformed {count_ratings} documents for 'restaurant_live_ratings'.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Data file '{data_file_path}' not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during transformation: {e}\")\n",
    "\n",
    "# --- Main execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    country_csv_file = 'Country-Code.csv' \n",
    "    data_csv_file = 'new_dataset.csv'     \n",
    "    \n",
    "    output_main_jsonl = 'restaurants_main.jsonl'\n",
    "    output_ratings_jsonl = 'restaurant_live_ratings.jsonl'\n",
    "\n",
    "    print(\"Starting data migration process for two collections...\")\n",
    "    \n",
    "    country_mapping = create_country_code_map(country_csv_file)\n",
    "    \n",
    "    if country_mapping:\n",
    "        print(f\"Country code map created with {len(country_mapping)} entries.\")\n",
    "        transform_data_to_two_collections(data_csv_file, country_mapping, output_main_jsonl, output_ratings_jsonl)\n",
    "        print(f\"\\nTransformation complete.\")\n",
    "        print(f\"Output for main data: {output_main_jsonl}\")\n",
    "        print(f\"Output for live ratings data: {output_ratings_jsonl}\")\n",
    "        print(f\"\\nYou can now import these JSONL files into their respective MongoDB collections.\")\n",
    "        print(f\"Remember to use the correct database and collection names in your 'mongoimport' commands.\")\n",
    "    else:\n",
    "        print(\"Could not create country mapping. Please check 'Country-Code.csv' and its headers.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
